import os
import yaml
import json
from neo4j import GraphDatabase
import time
import logging

# --- Configuration ---
NEO4J_URI = os.environ.get("NEO4J_URI", "bolt://neo4j:7687")
NEO4J_USER = os.environ.get("NEO4J_USER", "neo4j")
NEO4J_PASSWORD = os.environ.get("NEO4J_PASSWORD", "password123")
DEVICES_FILE = "/etc/topology/devices.yml"
TOPOLOGY_FILE = "/data/topology/topology.json"

logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')

# --- Edge Criticality Weights ---
# å®šä¹‰ä¸åŒå…³ç³»çš„"è‡´å‘½ç¨‹åº¦" (0.0 - 1.0)
EDGE_WEIGHTS = {
    'PHYSICAL': 1.0,    # HOSTED_ON (Pod -> Node) - ç‰©ç†ä¾èµ–ï¼Œç”Ÿæ­»ä¸Žå…±
    'SYNC_CALL': 0.9,   # RPC/REST (Service -> Service) - åŒæ­¥å¼ºä¾èµ–
    'CONFIG': 0.8,      # MOUNTS (Pod -> ConfigMap) - é…ç½®ä¾èµ–ï¼Œå¯åŠ¨å¿…éœ€
    'ASYNC_CALL': 0.5,  # MQ/PubSub (Service -> Kafka) - å¼‚æ­¥å¼±ä¾èµ–ï¼Œå¯ç¼“å†²
    'SIDECAR': 0.2,     # Logging/Metrics (Service -> Fluentd) - è¾…åŠ©åŠŸèƒ½
    'UNKNOWN': 0.5      # é»˜è®¤å…œåº•ç­–ç•¥
}

# å…³é”®ç«¯å£ç‰¹å¾åº“ (ç”¨äºŽæŽ¨æ–­åŒæ­¥/å¼‚æ­¥)
PORT_SIGNATURES = {
    'SYNC': [80, 443, 8080, 8443, 3306, 5432, 6379, 27017, 9200],  # Web, MySQL, Redis, MongoDB, ES
    'ASYNC': [9092, 9093, 9094, 5672, 1883, 61616, 4222],           # Kafka, RabbitMQ, MQTT, Artemis
}

# æ•°æ®åº“/å­˜å‚¨ç‰¹å¾å…³é”®è¯
DATABASE_KEYWORDS = ['mysql', 'postgres', 'redis', 'mongodb', 'elasticsearch', 'cassandra', 'influxdb']

# æ¶ˆæ¯é˜Ÿåˆ—ç‰¹å¾å…³é”®è¯
MQ_KEYWORDS = ['kafka', 'rabbitmq', 'activemq', 'pulsar', 'nats', 'mqtt', 'redis-stream']

class GraphBuilder:
    def __init__(self, uri, user, password):
        self._driver = None
        self.uri = uri
        self.user = user
        self.password = password
        self.connect()

    def connect(self):
        """Establishes connection to the Neo4j database."""
        for i in range(10): # Retry connection
            try:
                self._driver = GraphDatabase.driver(self.uri, auth=(self.user, self.password))
                self._driver.verify_connectivity()
                logging.info("Successfully connected to Neo4j.")
                return
            except Exception as e:
                logging.warning(f"Connection to Neo4j failed: {e}. Retrying in 10 seconds... ({i+1}/10)")
                time.sleep(10)
        logging.error("Could not connect to Neo4j after multiple retries. Exiting.")
        exit(1)


    def close(self):
        """Closes the database connection."""
        if self._driver is not None:
            self._driver.close()
            logging.info("Neo4j connection closed.")

    def run_query(self, query, parameters=None):
        """Runs a Cypher query."""
        with self._driver.session() as session:
            result = session.run(query, parameters)
            return [record for record in result]

    def setup_constraints(self):
        """Sets up unique constraints on node properties."""
        logging.info("Setting up database constraints...")
        query = "CREATE CONSTRAINT IF NOT EXISTS FOR (d:Device) REQUIRE d.name IS UNIQUE"
        self.run_query(query)
        logging.info("Constraint 'Device.name' is unique' ensured.")

    def import_devices(self):
        """Imports devices from a YAML file into Neo4j."""
        logging.info(f"Importing devices from {DEVICES_FILE}...")
        try:
            with open(DEVICES_FILE, 'r') as f:
                devices = yaml.safe_load(f)
        except FileNotFoundError:
            logging.error(f"Device file not found at {DEVICES_FILE}. Skipping device import.")
            return

        for device_name, properties in devices.get('devices', {}).items():
            device_type = properties.get('type', 'Unknown')
            query = (
                "MERGE (d:Device {name: $name}) "
                "SET d.ip = $ip, "
                "    d.type = $type, "
                "    d.site = $site, "
                "    d.last_seen = datetime(), "
                "    d.valid_from = CASE WHEN d.valid_from IS NULL THEN datetime() ELSE d.valid_from END"
            )
            parameters = {
                'name': device_name,
                'ip': properties.get('ip'),
                'type': device_type,
                'site': properties.get('site')
            }
            self.run_query(query, parameters)
            logging.info(f"Merged device node: {device_name} (type: {device_type})")

    def _calculate_criticality(self, rel_type, source_props, target_props):
        """
        å¯å‘å¼è®¡ç®—è¾¹æƒé‡

        æ ¹æ®å…³ç³»ç±»åž‹ã€ç«¯å£ã€èŠ‚ç‚¹åç§°ç­‰å¤šç»´åº¦ä¿¡æ¯æ™ºèƒ½æŽ¨æ–­è¾¹çš„è‡´å‘½ç¨‹åº¦ã€‚

        Args:
            rel_type: å…³ç³»ç±»åž‹ (e.g., 'CONNECTS_TO', 'HOSTED_ON')
            source_props: æºèŠ‚ç‚¹å±žæ€§
            target_props: ç›®æ ‡èŠ‚ç‚¹å±žæ€§

        Returns:
            float (0.0 - 1.0) - è¾¹çš„æƒé‡ï¼Œè¶Šé«˜è¡¨ç¤ºä¾èµ–è¶Šå¼º
        """
        # 1. ç‰©ç†å±‚ä¾èµ– (æœ€é«˜ä¼˜å…ˆçº§)
        if rel_type == 'HOSTED_ON':
            return EDGE_WEIGHTS['PHYSICAL']

        # 2. é…ç½®/å­˜å‚¨æŒ‚è½½
        if rel_type == 'MOUNTS':
            return EDGE_WEIGHTS['CONFIG']

        # 3. è¾…åŠ© Sidecar (é€šè¿‡åç§°åˆ¤æ–­)
        # å¦‚æžœç›®æ ‡æ˜¯ fluentd, filebeat, promtail, istio-proxy ç­‰
        target_name = target_props.get('name', '').lower()
        source_name = source_props.get('name', '').lower()

        if any(s in target_name for s in ['fluentd', 'filebeat', 'promtail', 'loki', 'otel-collector']):
            return EDGE_WEIGHTS['SIDECAR']

        # æ£€æŸ¥æºæ˜¯å¦æ˜¯ sidecar (istio-proxy, envoy)
        if any(s in source_name for s in ['istio-proxy', 'envoy', 'sidecar']):
            return EDGE_WEIGHTS['SIDECAR']

        # 4. ç½‘ç»œè°ƒç”¨ (CONNECTS_TO) - æ ¸å¿ƒé€»è¾‘
        if rel_type == 'CONNECTS_TO':
            # èŽ·å–ç«¯å£ä¿¡æ¯
            source_port = int(source_props.get('port', source_props.get('source_port', 0)))
            target_port = int(target_props.get('port', target_props.get('target_port', 0)))

            # è§„åˆ™ A: åŸºäºŽç«¯å£åˆ¤æ–­
            # ä¼˜å…ˆä½¿ç”¨ç›®æ ‡ç«¯å£
            port_to_check = target_port if target_port > 0 else source_port

            if port_to_check > 0:
                # æ£€æŸ¥æ˜¯å¦æ˜¯æ•°æ®åº“/å­˜å‚¨ç«¯å£ (åŒæ­¥å¼ºä¾èµ–)
                if port_to_check in PORT_SIGNATURES['SYNC']:
                    return EDGE_WEIGHTS['SYNC_CALL']

                # æ£€æŸ¥æ˜¯å¦æ˜¯æ¶ˆæ¯é˜Ÿåˆ—ç«¯å£ (å¼‚æ­¥å¼±ä¾èµ–)
                if port_to_check in PORT_SIGNATURES['ASYNC']:
                    return EDGE_WEIGHTS['ASYNC_CALL']

            # è§„åˆ™ B: åŸºäºŽèŠ‚ç‚¹åç§°/ç±»åž‹åˆ¤æ–­
            target_type = target_props.get('type', '').lower()

            # æ•°æ®åº“/å­˜å‚¨ -> åŒæ­¥å¼ºä¾èµ–
            if any(db in target_name or db in target_type for db in DATABASE_KEYWORDS):
                return EDGE_WEIGHTS['SYNC_CALL']

            # æ¶ˆæ¯é˜Ÿåˆ— -> å¼‚æ­¥å¼±ä¾èµ–
            if any(mq in target_name or mq in target_type for mq in MQ_KEYWORDS):
                return EDGE_WEIGHTS['ASYNC_CALL']

            # è§„åˆ™ C: é»˜è®¤ç­–ç•¥
            # å¦‚æžœç›®æ ‡è®¾å¤‡ç±»åž‹æ˜¯ 'router' æˆ– 'switch' (ç½‘ç»œè®¾å¤‡)ï¼Œè§†ä¸ºä¸­ç­‰ä¾èµ–
            if target_type in ['router', 'switch', 'firewall']:
                return 0.7

            # é»˜è®¤è§†ä¸ºåŒæ­¥è°ƒç”¨ (å®å¯è¯¯åˆ¤ä¸ºå¼ºä¾èµ–ï¼Œä¸å¯æ¼åˆ¤)
            return EDGE_WEIGHTS['SYNC_CALL']

        # 5. æœªçŸ¥å…³ç³»ç±»åž‹
        return EDGE_WEIGHTS['UNKNOWN']

    def import_topology(self):
        """Imports topology relationships from a JSON file with intelligent criticality calculation."""
        logging.info(f"Importing topology from {TOPOLOGY_FILE}...")
        try:
            with open(TOPOLOGY_FILE, 'r') as f:
                topology_data = json.load(f)
        except (FileNotFoundError, json.JSONDecodeError):
            logging.warning(f"Topology file not found or invalid at {TOPOLOGY_FILE}. Skipping topology import.")
            return

        for edge in topology_data.get('edges', []):
            source_device = edge.get('source')
            target_device = edge.get('target')
            source_port = edge.get('source_port')
            target_port = edge.get('target_port')

            if not all([source_device, target_device, source_port, target_port]):
                logging.warning(f"Skipping incomplete edge data: {edge}")
                continue

            # ðŸ”¥ æ™ºèƒ½è®¡ç®—è¾¹æƒé‡
            # èŽ·å–æºå’Œç›®æ ‡è®¾å¤‡çš„å±žæ€§ç”¨äºŽæŽ¨æ–­
            source_props = {'name': source_device, 'port': source_port}
            target_props = {'name': target_device, 'port': target_port}

            # å°è¯•ä»Ž devices.yml èŽ·å–æ›´å¤šå±žæ€§
            try:
                with open(DEVICES_FILE, 'r') as f:
                    devices = yaml.safe_load(f)
                    if source_device in devices.get('devices', {}):
                        source_props.update(devices['devices'][source_device])
                    if target_device in devices.get('devices', {}):
                        target_props.update(devices['devices'][target_device])
            except Exception as e:
                logging.debug(f"Could not load device properties for criticality calculation: {e}")

            # è®¡ç®—æƒé‡
            criticality = self._calculate_criticality('CONNECTS_TO', source_props, target_props)

            # æž„å»ºæŸ¥è¯¢å¹¶æ³¨å…¥æƒé‡
            query = (
                "MATCH (a:Device {name: $source_device}) "
                "MATCH (b:Device {name: $target_device}) "
                "MERGE (a)-[r:CONNECTS_TO]->(b) "
                "SET r.source_port = $source_port, "
                "    r.target_port = $target_port, "
                "    r.criticality = $criticality, "
                "    r.last_seen = datetime()"
            )
            parameters = {
                'source_device': source_device,
                'target_device': target_device,
                'source_port': source_port,
                'target_port': target_port,
                'criticality': criticality
            }

            self.run_query(query, parameters)

            # æ ¹æ®æƒé‡è®°å½•ä¸åŒçš„æ—¥å¿—çº§åˆ«
            if criticality >= 0.9:
                logging.info(f"Merged CRITICAL relationship: {source_device}({source_port}) -> {target_device}({target_port}) [criticality: {criticality}]")
            elif criticality >= 0.7:
                logging.info(f"Merged HIGH relationship: {source_device}({source_port}) -> {target_device}({target_port}) [criticality: {criticality}]")
            else:
                logging.debug(f"Merged relationship: {source_device}({source_port}) -> {target_device}({target_port}) [criticality: {criticality}]")

if __name__ == "__main__":
    logging.info("Starting AIOps Graph Builder...")
    builder = GraphBuilder(NEO4J_URI, NEO4J_USER, NEO4J_PASSWORD)
    builder.setup_constraints()
    builder.import_devices()
    builder.import_topology()
    builder.close()
    logging.info("Graph building process finished.")
